{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> TP: Information Retrieval Models<br> (Term Document Matrix and Vector Space Model) <br> KRY SENGHORT <br> ID: e20200706 <br> Group I4-AMS-B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1: Create a Term Document Matrix (TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Document Matrix (TDM):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithms</th>\n",
       "      <th>analyze</th>\n",
       "      <th>and</th>\n",
       "      <th>can</th>\n",
       "      <th>combines</th>\n",
       "      <th>communicating</th>\n",
       "      <th>complex</th>\n",
       "      <th>computer</th>\n",
       "      <th>data</th>\n",
       "      <th>datasets</th>\n",
       "      <th>...</th>\n",
       "      <th>interpreting</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>large</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>make</th>\n",
       "      <th>predictions</th>\n",
       "      <th>science</th>\n",
       "      <th>statistics</th>\n",
       "      <th>visualization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithms  analyze  and  can  combines  communicating  complex  computer  \\\n",
       "0           0        0    1    0         1              0        0         1   \n",
       "1           1        1    1    1         0              0        0         0   \n",
       "2           0        0    1    0         0              1        1         0   \n",
       "\n",
       "   data  datasets  ...  interpreting  knowledge  large  learning  machine  \\\n",
       "0     1         0  ...             0          1      0         0        0   \n",
       "1     0         1  ...             0          0      1         1        1   \n",
       "2     2         0  ...             1          0      0         0        0   \n",
       "\n",
       "   make  predictions  science  statistics  visualization  \n",
       "0     0            0        2           1              0  \n",
       "1     1            1        0           0              0  \n",
       "2     0            0        0           0              1  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the documents\n",
    "documents = [\n",
    "    \"Data science combines statistics, computer science, and domain knowledge.\",\n",
    "    \"Machine learning algorithms can analyze large datasets and make predictions.\",\n",
    "    \"Data visualization helps in interpreting complex data and communicating insights.\"\n",
    "]\n",
    "\n",
    "# Function to create a Term Document Matrix (TDM)\n",
    "def create_tdm(documents):\n",
    "    # Initialize CountVectorizer to tokenize and count term frequencies\n",
    "    vectorizer = CountVectorizer()\n",
    "    term_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # Convert the term matrix to a DataFrame for better readability\n",
    "    tdm_df = pd.DataFrame(term_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    return tdm_df\n",
    "\n",
    "# Create and print the Term Document Matrix\n",
    "tdm = create_tdm(documents)\n",
    "print(\"Term Document Matrix (TDM):\")\n",
    "tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2: Visualize the Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Document Matrix (TDM):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithms</th>\n",
       "      <th>analyze</th>\n",
       "      <th>and</th>\n",
       "      <th>can</th>\n",
       "      <th>combines</th>\n",
       "      <th>communicating</th>\n",
       "      <th>complex</th>\n",
       "      <th>computer</th>\n",
       "      <th>data</th>\n",
       "      <th>datasets</th>\n",
       "      <th>...</th>\n",
       "      <th>interpreting</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>large</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>make</th>\n",
       "      <th>predictions</th>\n",
       "      <th>science</th>\n",
       "      <th>statistics</th>\n",
       "      <th>visualization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            algorithms  analyze  and  can  combines  communicating  complex  \\\n",
       "Document 1           0        0    1    0         1              0        0   \n",
       "Document 2           1        1    1    1         0              0        0   \n",
       "Document 3           0        0    1    0         0              1        1   \n",
       "\n",
       "            computer  data  datasets  ...  interpreting  knowledge  large  \\\n",
       "Document 1         1     1         0  ...             0          1      0   \n",
       "Document 2         0     0         1  ...             0          0      1   \n",
       "Document 3         0     2         0  ...             1          0      0   \n",
       "\n",
       "            learning  machine  make  predictions  science  statistics  \\\n",
       "Document 1         0        0     0            0        2           1   \n",
       "Document 2         1        1     1            1        0           0   \n",
       "Document 3         0        0     0            0        0           0   \n",
       "\n",
       "            visualization  \n",
       "Document 1              0  \n",
       "Document 2              0  \n",
       "Document 3              1  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the documents\n",
    "documents = [\n",
    "    \"Data science combines statistics, computer science, and domain knowledge.\",\n",
    "    \"Machine learning algorithms can analyze large datasets and make predictions.\",\n",
    "    \"Data visualization helps in interpreting complex data and communicating insights.\"\n",
    "]\n",
    "\n",
    "# Function to create a Term Document Matrix (TDM)\n",
    "def create_tdm(documents):\n",
    "    vectorizer = CountVectorizer()\n",
    "    term_matrix = vectorizer.fit_transform(documents)\n",
    "    # Convert the term matrix to a DataFrame with terms as columns and document labels as rows\n",
    "    tdm_df = pd.DataFrame(term_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    # Set the document labels for clarity\n",
    "    tdm_df.index = [f\"Document {i+1}\" for i in range(len(documents))]\n",
    "    return tdm_df\n",
    "\n",
    "# Create and display the Term Document Matrix in a readable format\n",
    "tdm = create_tdm(documents)\n",
    "print(\"Term Document Matrix (TDM):\")\n",
    "tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3: Implement TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithms</th>\n",
       "      <th>analyze</th>\n",
       "      <th>and</th>\n",
       "      <th>can</th>\n",
       "      <th>combines</th>\n",
       "      <th>communicating</th>\n",
       "      <th>complex</th>\n",
       "      <th>computer</th>\n",
       "      <th>data</th>\n",
       "      <th>datasets</th>\n",
       "      <th>...</th>\n",
       "      <th>interpreting</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>large</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>make</th>\n",
       "      <th>predictions</th>\n",
       "      <th>science</th>\n",
       "      <th>statistics</th>\n",
       "      <th>visualization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317385</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634769</td>\n",
       "      <td>0.317385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 2</th>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.193164</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document 3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321704</td>\n",
       "      <td>0.321704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            algorithms   analyze       and       can  combines  communicating  \\\n",
       "Document 1    0.000000  0.000000  0.187453  0.000000  0.317385       0.000000   \n",
       "Document 2    0.327055  0.327055  0.193164  0.327055  0.000000       0.000000   \n",
       "Document 3    0.000000  0.000000  0.190004  0.000000  0.000000       0.321704   \n",
       "\n",
       "             complex  computer      data  datasets  ...  interpreting  \\\n",
       "Document 1  0.000000  0.317385  0.241379  0.000000  ...      0.000000   \n",
       "Document 2  0.000000  0.000000  0.000000  0.327055  ...      0.000000   \n",
       "Document 3  0.321704  0.000000  0.489329  0.000000  ...      0.321704   \n",
       "\n",
       "            knowledge     large  learning   machine      make  predictions  \\\n",
       "Document 1   0.317385  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "Document 2   0.000000  0.327055  0.327055  0.327055  0.327055     0.327055   \n",
       "Document 3   0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "\n",
       "             science  statistics  visualization  \n",
       "Document 1  0.634769    0.317385       0.000000  \n",
       "Document 2  0.000000    0.000000       0.000000  \n",
       "Document 3  0.000000    0.000000       0.321704  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the documents\n",
    "documents = [\n",
    "    \"Data science combines statistics, computer science, and domain knowledge.\",\n",
    "    \"Machine learning algorithms can analyze large datasets and make predictions.\",\n",
    "    \"Data visualization helps in interpreting complex data and communicating insights.\"\n",
    "]\n",
    "\n",
    "# Function to calculate TF-IDF for each term in each document\n",
    "def calculate_tfidf(documents):\n",
    "    # Initialize TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # Convert the TF-IDF matrix to a DataFrame for readability\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    # Set the document labels\n",
    "    tfidf_df.index = [f\"Document {i+1}\" for i in range(len(documents))]\n",
    "    return tfidf_df\n",
    "\n",
    "# Calculate and display the TF-IDF matrix\n",
    "tfidf_matrix = calculate_tfidf(documents)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4: Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking of documents based on cosine similarity to the query:\n",
      "Document 1: Similarity Score = 0.4459\n",
      "Document 3: Similarity Score = 0.2110\n",
      "Document 2: Similarity Score = 0.1610\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "documents = [\n",
    "    \"Data science combines statistics, computer science, and domain knowledge.\",\n",
    "    \"Machine learning algorithms can analyze large datasets and make predictions.\",\n",
    "    \"Data visualization helps in interpreting complex data and communicating insights.\"\n",
    "]\n",
    "# Define the query\n",
    "query = \"data science algorithms\"\n",
    "\n",
    "# Function to compute TF-IDF matrix for documents and a query\n",
    "def compute_tfidf(documents, query):\n",
    "    # Combine documents and query into one list\n",
    "    docs_with_query = documents + [query]\n",
    "    \n",
    "    # Initialize TfidfVectorizer and fit-transform on combined data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs_with_query)\n",
    "    \n",
    "    # Separate the document and query TF-IDF vectors\n",
    "    doc_tfidf = tfidf_matrix[:-1]  # All document vectors\n",
    "    query_tfidf = tfidf_matrix[-1]  # Query vector\n",
    "    return doc_tfidf, query_tfidf\n",
    "\n",
    "# Function to compute cosine similarity between the query and documents\n",
    "def rank_documents_by_similarity(doc_tfidf, query_tfidf):\n",
    "    # Calculate cosine similarity between query and each document\n",
    "    similarities = cosine_similarity(query_tfidf, doc_tfidf).flatten()\n",
    "    \n",
    "    # Rank documents by similarity\n",
    "    doc_ranking = sorted(enumerate(similarities, 1), key=lambda x: x[1], reverse=True)\n",
    "    return doc_ranking\n",
    "\n",
    "# Calculate TF-IDF and cosine similarity\n",
    "doc_tfidf, query_tfidf = compute_tfidf(documents, query)\n",
    "ranked_docs = rank_documents_by_similarity(doc_tfidf, query_tfidf)\n",
    "\n",
    "# Display results\n",
    "print(\"Ranking of documents based on cosine similarity to the query:\")\n",
    "for doc_num, score in ranked_docs:\n",
    "    print(f\"Document {doc_num}: Similarity Score = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5: Advanced Query Processing and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranking for Query 1 ('data scientist'):\n",
      "Document 3: Similarity Score = 0.2275\n",
      "Document 1: Similarity Score = 0.0990\n",
      "Document 2: Similarity Score = 0.0000\n",
      "\n",
      "Ranking for Query 2 ('machine learn'):\n",
      "Document 2: Similarity Score = 0.4279\n",
      "Document 1: Similarity Score = 0.0000\n",
      "Document 3: Similarity Score = 0.0000\n",
      "\n",
      "Ranking for Query 3 ('visualization of data'):\n",
      "Document 3: Similarity Score = 0.5111\n",
      "Document 1: Similarity Score = 0.1137\n",
      "Document 2: Similarity Score = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rog\n",
      "[nltk_data]     Strix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define the documents\n",
    "documents = [\n",
    "    \"Data science combines statistics, computer science, and domain knowledge.\",\n",
    "    \"Machine learning algorithms can analyze large datasets and make predictions.\",\n",
    "    \"Data visualization helps in interpreting complex data and communicating insights.\"\n",
    "]\n",
    "\n",
    "# Define the queries\n",
    "queries = [\n",
    "    \"data scientist\",\n",
    "    \"machine learn\",\n",
    "    \"visualization of data\"\n",
    "]\n",
    "\n",
    "# Function to preprocess text: lowercase, remove punctuation, apply stemming\n",
    "def preprocess_text(text):\n",
    "    # Lowercase and remove punctuation\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize and remove stopwords, then apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess documents and queries\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "preprocessed_queries = [preprocess_text(query) for query in queries]\n",
    "\n",
    "# Function to compute TF-IDF and cosine similarity\n",
    "def compute_tfidf_and_similarity(preprocessed_documents, preprocessed_queries):\n",
    "    # Combine documents and queries for TF-IDF transformation\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    all_texts = preprocessed_documents + preprocessed_queries\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # Split TF-IDF matrix into document vectors and query vectors\n",
    "    doc_tfidf = tfidf_matrix[:len(preprocessed_documents)]\n",
    "    query_tfidfs = tfidf_matrix[len(preprocessed_documents):]\n",
    "    \n",
    "    # Compute cosine similarity for each query against all documents\n",
    "    for i, query_vector in enumerate(query_tfidfs):\n",
    "        similarities = cosine_similarity(query_vector, doc_tfidf).flatten()\n",
    "        ranked_docs = sorted(enumerate(similarities, 1), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Print the ranking results for the query\n",
    "        print(f\"\\nRanking for Query {i+1} ('{queries[i]}'):\")\n",
    "        for doc_num, score in ranked_docs:\n",
    "            print(f\"Document {doc_num}: Similarity Score = {score:.4f}\")\n",
    "\n",
    "# Run the TF-IDF and similarity calculation\n",
    "compute_tfidf_and_similarity(preprocessed_documents, preprocessed_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> The End !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
